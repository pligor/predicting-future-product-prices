{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "#%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "from os import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from mylibs.jupyter_notebook_helper import show_graph\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib import learn\n",
    "import shutil\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = tf.float32\n",
    "seed = 16011984\n",
    "random_state = np.random.RandomState(seed=seed)\n",
    "config = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_time_series():\n",
    "    freq = (np.random.random()*0.5) + 0.1  # 0.1 to 0.6\n",
    "    ampl = np.random.random() + 0.5  # 0.5 to 1.5\n",
    "    x = np.sin(np.arange(0,SEQ_LEN) * freq) * ampl\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9f8AhPA21Ul9YAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41d4f02550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ii in range(5):\n",
    "    sns.tsplot(data=create_time_series())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_csv(filename, N):\n",
    "    with open(filename, 'w') as ofp:\n",
    "        for lineno in xrange(0, N):\n",
    "            seq = create_time_series()\n",
    "            line = \",\".join(map(str, seq))\n",
    "            ofp.write(line + '\\n')\n",
    "\n",
    "#to_csv('train.csv', 1000)  # 1000 sequences\n",
    "#to_csv('valid.csv',  50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULTS = [[0.] for x in xrange(0, SEQ_LEN)]  #just all zeros\n",
    "DEFAULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20 #hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TIMESERIES_COL = 'rawdata'  #we have only one column here\n",
    "N_OUTPUTS = 2  #in each sequence, 1-8 are features and 9-10 is label\n",
    "N_INPUTS = SEQ_LEN - N_OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset(filename, mode=tf.contrib.learn.ModeKeys.TRAIN):\n",
    "    \n",
    "    def _input_fn():\n",
    "        num_epochs = 100 if mode == tf.contrib.learn.ModeKeys.TRAIN else 1\n",
    "\n",
    "        #could be a path to one file or a file pattern\n",
    "        input_file_names = tf.train.match_filenames_once(filename)\n",
    "        print input_file_names\n",
    "\n",
    "        filename_queue = tf.train.string_input_producer(input_file_names,\n",
    "                                                        num_epochs=num_epochs,\n",
    "                                                        shuffle=True)\n",
    "\n",
    "        reader = tf.TextLineReader()\n",
    "        _, value = reader.read_up_to(filename_queue, num_records=BATCH_SIZE)\n",
    "\n",
    "        value_column = tf.expand_dims(value, -1)\n",
    "        print \"readcsv={}\".format(value_column)\n",
    "\n",
    "        #all data is a list of tensors\n",
    "        all_data = tf.decode_csv(value_column, record_defaults=DEFAULTS)\n",
    "        separation = len(all_data)- N_OUTPUTS\n",
    "        inputs = all_data[:separation]\n",
    "        label = all_data[separation:]\n",
    "\n",
    "        #from list of tensors to tensor\n",
    "        inputs = tf.concat(inputs, axis=1)\n",
    "        label = tf.concat(label, axis=1)\n",
    "        print 'inputs={}'.format(inputs)\n",
    "        print 'label={}'.format(label)\n",
    "\n",
    "        return {TIMESERIES_COL: inputs}, label  #dict of features, label <-- prescribed\n",
    "    \n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testfun = read_dataset('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'matching_filenames:0' shape=<unknown> dtype=string_ref>\n",
      "readcsv=Tensor(\"ExpandDims:0\", shape=(?, 1), dtype=string)\n",
      "inputs=Tensor(\"concat:0\", shape=(?, 8), dtype=float32)\n",
      "label=Tensor(\"concat_1:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()  # create new graph\n",
    "\n",
    "with graph.as_default():\n",
    "    testfun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:900px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph2017-06-10_10-53-34&quot;).pbtxt = 'node {\\n  name: &quot;matching_filenames/MatchingFiles/pattern&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;train.csv&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;matching_filenames/MatchingFiles&quot;\\n  op: &quot;MatchingFiles&quot;\\n  input: &quot;matching_filenames/MatchingFiles/pattern&quot;\\n}\\nnode {\\n  name: &quot;matching_filenames&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;matching_filenames/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;matching_filenames&quot;\\n  input: &quot;matching_filenames/MatchingFiles&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@matching_filenames&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;matching_filenames/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;matching_filenames&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@matching_filenames&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/Size&quot;\\n  op: &quot;Size&quot;\\n  input: &quot;matching_filenames/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/Greater/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/Greater&quot;\\n  op: &quot;Greater&quot;\\n  input: &quot;input_producer/Size&quot;\\n  input: &quot;input_producer/Greater/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/Assert/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;string_input_producer requires a non-null input tensor&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/Assert/Assert/data_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;string_input_producer requires a non-null input tensor&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/Assert/Assert&quot;\\n  op: &quot;Assert&quot;\\n  input: &quot;input_producer/Greater&quot;\\n  input: &quot;input_producer/Assert/Assert/data_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;summarize&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/Identity&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;matching_filenames/read&quot;\\n  input: &quot;^input_producer/Assert/Assert&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/RandomShuffle&quot;\\n  op: &quot;RandomShuffle&quot;\\n  input: &quot;input_producer/Identity&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/limit_epochs/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/limit_epochs/epochs&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/limit_epochs/epochs/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;input_producer/limit_epochs/epochs&quot;\\n  input: &quot;input_producer/limit_epochs/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_producer/limit_epochs/epochs&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/limit_epochs/epochs/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;input_producer/limit_epochs/epochs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_producer/limit_epochs/epochs&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/limit_epochs/CountUpTo&quot;\\n  op: &quot;CountUpTo&quot;\\n  input: &quot;input_producer/limit_epochs/epochs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@input_producer/limit_epochs/epochs&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;limit&quot;\\n    value {\\n      i: 100\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/limit_epochs&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;input_producer/RandomShuffle&quot;\\n  input: &quot;^input_producer/limit_epochs/CountUpTo&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer&quot;\\n  op: &quot;FIFOQueueV2&quot;\\n  attr {\\n    key: &quot;capacity&quot;\\n    value {\\n      i: 32\\n    }\\n  }\\n  attr {\\n    key: &quot;component_types&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;shapes&quot;\\n    value {\\n      list {\\n        shape {\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/input_producer_EnqueueMany&quot;\\n  op: &quot;QueueEnqueueManyV2&quot;\\n  input: &quot;input_producer&quot;\\n  input: &quot;input_producer/limit_epochs&quot;\\n  attr {\\n    key: &quot;Tcomponents&quot;\\n    value {\\n      list {\\n        type: DT_STRING\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;timeout_ms&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/input_producer_Close&quot;\\n  op: &quot;QueueCloseV2&quot;\\n  input: &quot;input_producer&quot;\\n  attr {\\n    key: &quot;cancel_pending_enqueues&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/input_producer_Close_1&quot;\\n  op: &quot;QueueCloseV2&quot;\\n  input: &quot;input_producer&quot;\\n  attr {\\n    key: &quot;cancel_pending_enqueues&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/input_producer_Size&quot;\\n  op: &quot;QueueSizeV2&quot;\\n  input: &quot;input_producer&quot;\\n}\\nnode {\\n  name: &quot;input_producer/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;input_producer/input_producer_Size&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/mul/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.03125\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;input_producer/Cast&quot;\\n  input: &quot;input_producer/mul/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/fraction_of_32_full/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;input_producer/fraction_of_32_full&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;input_producer/fraction_of_32_full&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;input_producer/fraction_of_32_full/tags&quot;\\n  input: &quot;input_producer/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;TextLineReaderV2&quot;\\n  op: &quot;TextLineReaderV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;skip_header_lines&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ReaderReadUpToV2/num_records&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 20\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ReaderReadUpToV2&quot;\\n  op: &quot;ReaderReadUpToV2&quot;\\n  input: &quot;TextLineReaderV2&quot;\\n  input: &quot;input_producer&quot;\\n  input: &quot;ReaderReadUpToV2/num_records&quot;\\n}\\nnode {\\n  name: &quot;ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;ReaderReadUpToV2:1&quot;\\n  input: &quot;ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;DecodeCSV/record_defaults_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;DecodeCSV/record_defaults_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;DecodeCSV/record_defaults_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;DecodeCSV/record_defaults_3&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;DecodeCSV/record_defaults_4&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;DecodeCSV/record_defaults_5&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;DecodeCSV/record_defaults_6&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;DecodeCSV/record_defaults_7&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;DecodeCSV/record_defaults_8&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;DecodeCSV/record_defaults_9&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;DecodeCSV&quot;\\n  op: &quot;DecodeCSV&quot;\\n  input: &quot;ExpandDims&quot;\\n  input: &quot;DecodeCSV/record_defaults_0&quot;\\n  input: &quot;DecodeCSV/record_defaults_1&quot;\\n  input: &quot;DecodeCSV/record_defaults_2&quot;\\n  input: &quot;DecodeCSV/record_defaults_3&quot;\\n  input: &quot;DecodeCSV/record_defaults_4&quot;\\n  input: &quot;DecodeCSV/record_defaults_5&quot;\\n  input: &quot;DecodeCSV/record_defaults_6&quot;\\n  input: &quot;DecodeCSV/record_defaults_7&quot;\\n  input: &quot;DecodeCSV/record_defaults_8&quot;\\n  input: &quot;DecodeCSV/record_defaults_9&quot;\\n  attr {\\n    key: &quot;OUT_TYPE&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;field_delim&quot;\\n    value {\\n      s: &quot;,&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;DecodeCSV&quot;\\n  input: &quot;DecodeCSV:1&quot;\\n  input: &quot;DecodeCSV:2&quot;\\n  input: &quot;DecodeCSV:3&quot;\\n  input: &quot;DecodeCSV:4&quot;\\n  input: &quot;DecodeCSV:5&quot;\\n  input: &quot;DecodeCSV:6&quot;\\n  input: &quot;DecodeCSV:7&quot;\\n  input: &quot;concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 8\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;DecodeCSV:8&quot;\\n  input: &quot;DecodeCSV:9&quot;\\n  input: &quot;concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nversions {\\n  producer: 21\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph2017-06-10_10-53-34&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is the state size\n",
    "LSTM_SIZE = 3  #number of hidden layers in each of the LSTM cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the inference model\n",
    "def simple_rnn(features, targets, mode):\n",
    "    # 0. Reformat input shape to become a sequence\n",
    "    xx = tf.split(features[TIMESERIES_COL], N_INPUTS, 1)\n",
    "    print len(xx)\n",
    "    print \"xx={}\".format(xx[0])\n",
    "    print\n",
    "    \n",
    "    #1. configure the RNN\n",
    "    lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE, forget_bias=1.)\n",
    "    outputs, _ = rnn.static_rnn(cell=lstm_cell, inputs=xx, dtype=dtype)\n",
    "    \n",
    "    #slice to keep only the last cell of the RNN\n",
    "    outputs = outputs[-1]\n",
    "    print \"last out: {}\".format(outputs)\n",
    "    #this is of length 3 because this is the size of layers inside the LSTM cell\n",
    "    \n",
    "    weight = tf.Variable(tf.random_normal([LSTM_SIZE, N_OUTPUTS]))\n",
    "    bias = tf.Variable(tf.random_normal([N_OUTPUTS]))\n",
    "    predictions = tf.matmul(outputs, weight) + bias\n",
    "    \n",
    "    \n",
    "    #2. define the loss function for training / evaluation\n",
    "    loss = tf.losses.mean_squared_error(labels=targets, predictions=predictions)\n",
    "    \n",
    "    eval_metric_ops = {\n",
    "        \"rmse\": tf.metrics.root_mean_squared_error(labels=targets, predictions=predictions)\n",
    "    }\n",
    "    \n",
    "    #3. Define the training operation/optimizer\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss, global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=0.01,\n",
    "        optimizer=\"SGD\"\n",
    "    )\n",
    "    \n",
    "    #4. Create predictions\n",
    "    predictions_dict = {\"predicted\": predictions}\n",
    "    \n",
    "    #5. return ModelFnOps\n",
    "    return learn.ModelFnOps(\n",
    "        mode=mode,\n",
    "        predictions=predictions_dict,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "xx=Tensor(\"split:0\", shape=(?, 1), dtype=float32)\n",
      "\n",
      "last out: Tensor(\"rnn/basic_lstm_cell_7/mul_2:0\", shape=(?, 3), dtype=float32)\n",
      "ModelFnOps(predictions={'predicted': <tf.Tensor 'add:0' shape=(?, 2) dtype=float32>}, loss=<tf.Tensor 'mean_squared_error/value:0' shape=() dtype=float32>, train_op=<tf.Operation 'OptimizeLoss/control_dependency' type=Identity>, eval_metric_ops={'rmse': (<tf.Tensor 'Sqrt:0' shape=() dtype=float32>, <tf.Tensor 'Sqrt_1:0' shape=() dtype=float32>)}, output_alternatives=None, training_chief_hooks=[], training_hooks=[], scaffold=None)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()  # create new graph\n",
    "\n",
    "with graph.as_default():\n",
    "    inputs = tf.placeholder(dtype=dtype, shape=(None, 8), name=\"stream\")\n",
    "    targets = tf.placeholder(dtype=dtype, shape=(None, 2), name=\"targets\")\n",
    "    \n",
    "    print simple_rnn(features={TIMESERIES_COL: inputs}, targets=targets, mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train():\n",
    "    return read_dataset('train.csv', mode=tf.contrib.learn.ModeKeys.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_valid():\n",
    "    return read_dataset('valid.csv', mode=tf.contrib.learn.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment_fn(output_dir):\n",
    "    \"\"\"run experiment\"\"\"\n",
    "    \n",
    "    estimator = learn.Estimator(model_fn=simple_rnn, model_dir=output_dir)\n",
    "    \n",
    "    return learn.Experiment(estimator, train_input_fn=get_train(),\n",
    "                            eval_input_fn=get_valid(), eval_metrics= {\n",
    "                                \"rmse\": learn.MetricSpec(\n",
    "                                    metric_fn=tf.metrics.root_mean_squared_error\n",
    "                                )\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'outputdir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree(OUTPUT_DIR, ignore_errors=True)  #start fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': None, '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa817409710>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': ''}\n",
      "WARNING:tensorflow:From /home/studenthp/anaconda2/envs/dis/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:267: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "<tf.Variable 'matching_filenames:0' shape=<unknown> dtype=string_ref>\n",
      "readcsv=Tensor(\"ExpandDims:0\", shape=(?, 1), dtype=string)\n",
      "inputs=Tensor(\"concat:0\", shape=(?, 8), dtype=float32)\n",
      "label=Tensor(\"concat_1:0\", shape=(?, 2), dtype=float32)\n",
      "xx=[<tf.Tensor 'split:0' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:1' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:2' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:3' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:4' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:5' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:6' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:7' shape=(?, 1) dtype=float32>]\n",
      "last out: Tensor(\"rnn/basic_lstm_cell_7/mul_2:0\", shape=(?, 3), dtype=float32)\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into outputdir/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.63465, step = 1\n",
      "<tf.Variable 'matching_filenames:0' shape=<unknown> dtype=string_ref>\n",
      "readcsv=Tensor(\"ExpandDims:0\", shape=(?, 1), dtype=string)\n",
      "inputs=Tensor(\"concat:0\", shape=(?, 8), dtype=float32)\n",
      "label=Tensor(\"concat_1:0\", shape=(?, 2), dtype=float32)\n",
      "xx=[<tf.Tensor 'split:0' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:1' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:2' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:3' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:4' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:5' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:6' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:7' shape=(?, 1) dtype=float32>]\n",
      "last out: Tensor(\"rnn/basic_lstm_cell_7/mul_2:0\", shape=(?, 3), dtype=float32)\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-09-15:28:48\n",
      "INFO:tensorflow:Restoring parameters from outputdir/model.ckpt-1\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-09-15:28:48\n",
      "INFO:tensorflow:Saving dict for global step 1: RMSE = 1.41687, global_step = 1, loss = 2.10078, rmse = 1.41687\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "INFO:tensorflow:Validation (step 1): loss = 2.10078, rmse = 1.41687, global_step = 1, RMSE = 1.41687\n",
      "INFO:tensorflow:global_step/sec: 41.0998\n",
      "INFO:tensorflow:loss = 0.417606, step = 101 (2.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.539\n",
      "INFO:tensorflow:loss = 0.325984, step = 201 (0.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.873\n",
      "INFO:tensorflow:loss = 0.28163, step = 301 (0.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.368\n",
      "INFO:tensorflow:loss = 0.246528, step = 401 (0.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.425\n",
      "INFO:tensorflow:loss = 0.217216, step = 501 (0.906 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.871\n",
      "INFO:tensorflow:loss = 0.192553, step = 601 (0.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.965\n",
      "INFO:tensorflow:loss = 0.171816, step = 701 (0.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.9\n",
      "INFO:tensorflow:loss = 0.154449, step = 801 (0.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.016\n",
      "INFO:tensorflow:loss = 0.13997, step = 901 (0.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.554\n",
      "INFO:tensorflow:loss = 0.127942, step = 1001 (0.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.383\n",
      "INFO:tensorflow:loss = 0.117969, step = 1101 (0.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.925\n",
      "INFO:tensorflow:loss = 0.109696, step = 1201 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.598\n",
      "INFO:tensorflow:loss = 0.102816, step = 1301 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.204\n",
      "INFO:tensorflow:loss = 0.0970707, step = 1401 (0.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.757\n",
      "INFO:tensorflow:loss = 0.0922424, step = 1501 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.132\n",
      "INFO:tensorflow:loss = 0.0881542, step = 1601 (0.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.681\n",
      "INFO:tensorflow:loss = 0.0846625, step = 1701 (0.836 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.83\n",
      "INFO:tensorflow:loss = 0.0816519, step = 1801 (0.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.583\n",
      "INFO:tensorflow:loss = 0.0790301, step = 1901 (0.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.629\n",
      "INFO:tensorflow:loss = 0.0767237, step = 2001 (0.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.51\n",
      "INFO:tensorflow:loss = 0.074674, step = 2101 (0.727 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.545\n",
      "INFO:tensorflow:loss = 0.0728347, step = 2201 (0.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.428\n",
      "INFO:tensorflow:loss = 0.0711688, step = 2301 (0.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.899\n",
      "INFO:tensorflow:loss = 0.0696467, step = 2401 (0.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.311\n",
      "INFO:tensorflow:loss = 0.068245, step = 2501 (0.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.751\n",
      "INFO:tensorflow:loss = 0.0669446, step = 2601 (0.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.335\n",
      "INFO:tensorflow:loss = 0.0657302, step = 2701 (0.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.831\n",
      "INFO:tensorflow:loss = 0.0645894, step = 2801 (0.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.47\n",
      "INFO:tensorflow:loss = 0.0635117, step = 2901 (0.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.468\n",
      "INFO:tensorflow:loss = 0.0624889, step = 3001 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.533\n",
      "INFO:tensorflow:loss = 0.0615136, step = 3101 (0.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.124\n",
      "INFO:tensorflow:loss = 0.06058, step = 3201 (0.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.175\n",
      "INFO:tensorflow:loss = 0.0596828, step = 3301 (0.942 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.229\n",
      "INFO:tensorflow:loss = 0.0588176, step = 3401 (0.838 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.268\n",
      "INFO:tensorflow:loss = 0.0579804, step = 3501 (0.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.745\n",
      "INFO:tensorflow:loss = 0.0571678, step = 3601 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.315\n",
      "INFO:tensorflow:loss = 0.0563768, step = 3701 (0.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.427\n",
      "INFO:tensorflow:loss = 0.0556044, step = 3801 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.425\n",
      "INFO:tensorflow:loss = 0.0548482, step = 3901 (0.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.484\n",
      "INFO:tensorflow:loss = 0.0541057, step = 4001 (0.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.154\n",
      "INFO:tensorflow:loss = 0.0533748, step = 4101 (0.818 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.845\n",
      "INFO:tensorflow:loss = 0.0526535, step = 4201 (0.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.406\n",
      "INFO:tensorflow:loss = 0.0519397, step = 4301 (0.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.94\n",
      "INFO:tensorflow:loss = 0.0512317, step = 4401 (0.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.041\n",
      "INFO:tensorflow:loss = 0.0505278, step = 4501 (0.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.861\n",
      "INFO:tensorflow:loss = 0.0498262, step = 4601 (0.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.746\n",
      "INFO:tensorflow:loss = 0.0491253, step = 4701 (0.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.561\n",
      "INFO:tensorflow:loss = 0.0484237, step = 4801 (0.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.047\n",
      "INFO:tensorflow:loss = 0.0477197, step = 4901 (0.741 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into outputdir/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0444429.\n",
      "<tf.Variable 'matching_filenames:0' shape=<unknown> dtype=string_ref>\n",
      "readcsv=Tensor(\"ExpandDims:0\", shape=(?, 1), dtype=string)\n",
      "inputs=Tensor(\"concat:0\", shape=(?, 8), dtype=float32)\n",
      "label=Tensor(\"concat_1:0\", shape=(?, 2), dtype=float32)\n",
      "xx=[<tf.Tensor 'split:0' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:1' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:2' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:3' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:4' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:5' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:6' shape=(?, 1) dtype=float32>, <tf.Tensor 'split:7' shape=(?, 1) dtype=float32>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last out: Tensor(\"rnn/basic_lstm_cell_7/mul_2:0\", shape=(?, 3), dtype=float32)\n",
      "INFO:tensorflow:Starting evaluation at 2017-06-09-15:29:28\n",
      "INFO:tensorflow:Restoring parameters from outputdir/model.ckpt-5000\n",
      "INFO:tensorflow:Evaluation [1/100]\n",
      "INFO:tensorflow:Evaluation [2/100]\n",
      "INFO:tensorflow:Evaluation [3/100]\n",
      "INFO:tensorflow:Finished evaluation at 2017-06-09-15:29:28\n",
      "INFO:tensorflow:Saving dict for global step 5000: RMSE = 0.246303, global_step = 5000, loss = 0.0671288, rmse = 0.246303\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'RMSE': 0.24630338,\n",
       "  'global_step': 5000,\n",
       "  'loss': 0.067128815,\n",
       "  'rmse': 0.24630338},\n",
       " [])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#takes as inputs the experiment function and its arguments\n",
    "learn_runner.run(experiment_fn=experiment_fn, output_dir=OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    print sess.run(tf.constant([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.701171875"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studenthp/anaconda2/envs/dis/lib/python2.7/site-packages/keras/models.py:826: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4232 samples, validate on 223 samples\n",
      "Epoch 1/1\n",
      "4232/4232 [==============================] - 6s - loss: 0.1963 - val_loss: 0.0306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e827b03d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=512, nb_epoch=epochs, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
